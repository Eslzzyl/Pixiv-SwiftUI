import logging
import os
import time
from dataclasses import dataclass
from typing import Dict, List, Optional

from .api.search import SearchAPI
from .models import PixivTag

logger = logging.getLogger(__name__)


@dataclass
class DFSNode:
    """æ·±åº¦ä¼˜å…ˆæœç´¢èŠ‚ç‚¹"""

    tag_name: str
    depth: int
    parent: Optional[str] = None


@dataclass
class CollectionStats:
    """æ”¶é›†ç»Ÿè®¡ä¿¡æ¯"""

    tags_found: int = 0
    illusts_processed: int = 0
    tags_searched: int = 0
    depth_reached: int = 0


class RecommendationBasedCollector:
    """åŸºäºæ¨èæµçš„æ·±åº¦ä¼˜å…ˆæ ‡ç­¾æ”¶é›†å™¨"""

    def __init__(
        self,
        search_api: SearchAPI,
        storage,
        max_depth: int = 3,
    ):
        self.search_api = search_api
        self.storage = storage
        self.max_depth = max_depth
        self.save_interval = int(
            os.getenv("SAVE_INTERVAL", "20")
        )  # ä»ç¯å¢ƒå˜é‡è¯»å–ä¿å­˜é—´éš”
        self.new_tags_count = 0

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = CollectionStats()

        # åœæ­¢æ ‡å¿—
        self.should_stop_func = None

    def set_stop_flag(self, should_stop_func):
        """è®¾ç½®åœæ­¢æ ‡å¿—æ£€æŸ¥å‡½æ•°"""
        self.should_stop_func = should_stop_func

    def check_stop(self):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢"""
        if hasattr(self, "should_stop_func") and self.should_stop_func():
            return True
        # å°è¯•ä»mainæ¨¡å—è·å–å…¨å±€åœæ­¢æ ‡å¿—
        try:
            import main

            return getattr(main, "should_stop", False)
        except (ImportError, AttributeError):
            return False

    def _should_save_now(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ç°åœ¨ä¿å­˜ï¼ˆSQLite æ¨¡å¼ä¸‹ç”± _dfs_collect_tags å¤„ç†ï¼‰"""
        return False

    def _try_save(self, force: bool = False):
        """å°è¯•ä¿å­˜ï¼ˆSQLite æ¨¡å¼ï¼šå¼ºåˆ¶åŒæ­¥ï¼›JSON æ¨¡å¼ï¼šåŸºäºæœç´¢æ¬¡æ•°ï¼‰"""
        if force:
            if self.storage.mode == "sqlite":
                self.storage.force_sync()
                logger.info(
                    f"Force-saved {self.storage.get_memory_count()} tags to database"
                )
            else:
                self.storage.save_from_memory()
                logger.info(
                    f"Force-saved {self.storage.get_memory_count()} tags to file"
                )
            return True

        if self.storage.mode == "sqlite":
            # SQLite æ¨¡å¼ï¼šåŒæ­¥ç”± _dfs_collect_tags ä¸­çš„æœç´¢è®¡æ•°å¤„ç†
            return True
        else:
            # JSON æ¨¡å¼ï¼šåŸºäºæœç´¢æ¬¡æ•°è§¦å‘ä¿å­˜
            if self.stats.tags_searched % self.save_interval == 0:
                try:
                    self.storage.save_from_memory()
                    logger.info(
                        f"Auto-saved {self.storage.get_memory_count()} tags to file"
                    )
                    return True
                except Exception as e:
                    logger.error(f"Failed to auto-save: {e}")
                    return False
        return False

    def _extract_tags_from_illust(self, illust: Dict) -> List[PixivTag]:
        """ä»æ’ç”»æ•°æ®ä¸­æå–æ‰€æœ‰æ ‡ç­¾ï¼ˆåŒ…æ‹¬å·²å­˜åœ¨çš„ï¼‰"""
        tags = []
        illust_tags = illust.get("tags", [])

        for tag_data in illust_tags:
            tag_name = tag_data.get("name")
            if tag_name:
                tag = PixivTag(
                    name=tag_name, official_translation=tag_data.get("translated_name")
                )
                tags.append(tag)

        return tags

    def _process_illusts(self, illusts: List[Dict], current_depth: int) -> List[str]:
        """å¤„ç†æ’ç”»åˆ—è¡¨ï¼Œè¿”å›æ–°å‘ç°çš„æ ‡ç­¾"""
        new_tag_names = []

        for illust in illusts:
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            if self.check_stop():
                break

            illust_id = illust.get("id")
            if not illust_id:
                continue
            self.stats.illusts_processed += 1

            # è·å–æ’ç”»çš„æ‰€æœ‰æ ‡ç­¾
            illust_tags = illust.get("tags", [])
            if not illust_tags:
                continue

            # åˆ†ç±»æ ‡ç­¾ï¼šæ–°å¢å’Œé‡å¤
            new_tags_for_illust = []
            existing_tags_for_illust = []
            existing_tag_details = []  # å­˜å‚¨é‡å¤æ ‡ç­¾çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«é¢‘ç‡ï¼‰

            for tag_data in illust_tags:
                tag_name = tag_data.get("name")
                if not tag_name:
                    continue

                if not self.storage.is_tag_in_memory(tag_name):
                    # æ–°æ ‡ç­¾
                    tag = PixivTag(
                        name=tag_name,
                        official_translation=tag_data.get("translated_name"),
                        frequency=1,  # æ–°æ ‡ç­¾åˆå§‹é¢‘ç‡ä¸º1
                    )
                    new_tags_for_illust.append(tag)
                    new_tag_names.append(tag_name)
                else:
                    # é‡å¤æ ‡ç­¾ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯å¹¶å¢åŠ é¢‘ç‡
                    existing_tags_for_illust.append(tag_name)
                    # è·å–å½“å‰é¢‘ç‡å¹¶æ›´æ–°
                    current_freq = self.storage.get_tag_frequency(tag_name)
                    existing_tag_details.append(
                        f"'{tag_name}'(é¢‘ç‡:{current_freq + 1})"
                    )
                    self.storage.increment_tag_frequency(tag_name, 1)

            # å°†æ–°æ ‡ç­¾æ·»åŠ åˆ°å†…å­˜
            if new_tags_for_illust:
                added_count = self.storage.add_tags_to_memory(new_tags_for_illust)
                self.new_tags_count += added_count
                self.stats.tags_found += added_count

            # è¾“å‡ºæ±‡æ€»æ—¥å¿—
            if new_tags_for_illust or existing_tags_for_illust:
                new_tag_strs = []
                for tag in new_tags_for_illust:
                    if tag.official_translation:
                        new_tag_strs.append(
                            f"'{tag.name}'->'{tag.official_translation}'(é¢‘ç‡:{tag.frequency})"
                        )
                    else:
                        new_tag_strs.append(f"'{tag.name}'(é¢‘ç‡:{tag.frequency})")

                # ä½¿ç”¨åŒ…å«é¢‘ç‡çš„è¯¦ç»†ä¿¡æ¯
                existing_tag_strs = existing_tag_details[:5]  # é™åˆ¶é‡å¤æ ‡ç­¾æ˜¾ç¤ºæ•°é‡
                if len(existing_tags_for_illust) > 5:
                    existing_tag_strs.append(
                        f"...ç­‰{len(existing_tags_for_illust) - 5}ä¸ª"
                    )

                if new_tags_for_illust and existing_tags_for_illust:
                    new_tags_summary = ", ".join(new_tag_strs)
                    existing_tags_summary = ", ".join(existing_tag_strs)
                    logger.info(
                        f"[æ·±åº¦{current_depth}] æ’ç”»{illust_id}: æ–°å¢{len(new_tags_for_illust)}ä¸ªæ ‡ç­¾ {new_tags_summary} | "
                        f"é‡å¤{len(existing_tags_for_illust)}ä¸ªæ ‡ç­¾ {existing_tags_summary}"
                    )
                elif new_tags_for_illust:
                    new_tags_summary = ", ".join(new_tag_strs)
                    logger.info(
                        f"[æ·±åº¦{current_depth}] æ’ç”»{illust_id}: æ–°å¢{len(new_tags_for_illust)}ä¸ªæ ‡ç­¾ {new_tags_summary}"
                    )
                elif existing_tags_for_illust:
                    existing_tags_summary = ", ".join(existing_tag_strs)
                    logger.debug(
                        f"[æ·±åº¦{current_depth}] æ’ç”»{illust_id}: é‡å¤{len(existing_tags_for_illust)}ä¸ªæ ‡ç­¾ {existing_tags_summary}"
                    )

        return new_tag_names

    def _dfs_collect_tags(self, start_tags: List[str]) -> CollectionStats:
        """æ·±åº¦ä¼˜å…ˆæ”¶é›†æ ‡ç­¾"""
        # ä½¿ç”¨æ ˆå®ç°æ·±åº¦ä¼˜å…ˆæœç´¢
        stack: List[DFSNode] = []

        # åˆå§‹åŒ–æ ˆï¼Œå°†èµ·å§‹æ ‡ç­¾ä½œä¸ºæ·±åº¦0
        for tag_name in start_tags:
            stack.append(DFSNode(tag_name=tag_name, depth=0))

        while stack and not self.check_stop():
            node = stack.pop()
            current_tag = node.tag_name
            current_depth = node.depth

            # æ›´æ–°ç»Ÿè®¡
            self.stats.tags_searched += 1
            self.stats.depth_reached = max(self.stats.depth_reached, current_depth)

            logger.info(f"æœç´¢æ ‡ç­¾ '{current_tag}' (æ·±åº¦: {current_depth})")

            # æŒ‰æ ‡ç­¾æœç´¢æ’ç”»
            time.sleep(1)  # è¯·æ±‚é—´éš”
            try:
                illusts = self.search_api.search_illust_by_tag(current_tag, limit=20)
            except Exception as e:
                if "429" in str(e) or "Too Many Requests" in str(e):
                    logger.error(f"429é”™è¯¯å¤„ç†å¤±è´¥: {e}")
                    logger.info("ç¨‹åºå°†å°è¯•ä»å…¶ä»–æ ‡ç­¾ç»§ç»­...")
                    continue
                else:
                    logger.error(f"æœç´¢æ ‡ç­¾ '{current_tag}' æ—¶å‡ºé”™: {e}")
                    continue

            if not illusts:
                logger.debug(f"æ ‡ç­¾ '{current_tag}' æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ’ç”»")
                continue

            # å¤„ç†æ’ç”»ï¼Œæå–æ–°æ ‡ç­¾
            new_tag_names = self._process_illusts(illusts, current_depth)

            # å°†æ–°æ ‡ç­¾åŠ å…¥æ ˆï¼ˆæ·±åº¦+1ï¼‰
            if current_depth < self.max_depth:
                for tag_name in new_tag_names:
                    stack.append(
                        DFSNode(
                            tag_name=tag_name,
                            depth=current_depth + 1,
                            parent=current_tag,
                        )
                    )

            # æ¯ N æ¬¡æœç´¢åŒæ­¥ä¸€æ¬¡ï¼ˆåŸºäºæœç´¢æ¬¡æ•°ï¼Œè€Œéæ’ç”»è®¡æ•°ï¼‰
            self.stats.tags_searched += 1
            if self.stats.tags_searched % self.save_interval == 0:
                if self.storage.mode == "sqlite":
                    self.storage.sync_to_database()
                    logger.debug(
                        f"è‡ªåŠ¨åŒæ­¥: å·²æœç´¢ {self.stats.tags_searched} ä¸ªæ ‡ç­¾ï¼Œ"
                        f"å¾…åŒæ­¥æ–°æ ‡ç­¾ {len(self.storage.pending_new_tags)}ï¼Œ"
                        f"å¾…åŒæ­¥é¢‘ç‡æ“ä½œ {len(self.storage.pending_freq_ops)}"
                    )
                else:
                    self.storage.save_from_memory()
                    logger.info(
                        f"Auto-saved {self.storage.get_memory_count()} tags to file"
                    )

            # æ¯10ä¸ªæœç´¢è¾“å‡ºä¸€æ¬¡è¿›åº¦
            if self.stats.tags_searched % 10 == 0:
                logger.info(
                    f"ğŸ“ˆ è¿›åº¦: å·²æœç´¢ {self.stats.tags_searched} ä¸ªæ ‡ç­¾ï¼Œ"
                    f"å‘ç° {self.stats.tags_found} ä¸ªæ–°æ ‡ç­¾ï¼Œ"
                    f"å¤„ç† {self.stats.illusts_processed} ä¸ªæ’ç”»ï¼Œ"
                    f"æœ€å¤§æ·±åº¦ {self.stats.depth_reached}"
                )

        return self.stats

    def collect_from_recommendations(self) -> int:
        """ä»æ¨èæµå¼€å§‹æ·±åº¦ä¼˜å…ˆæ”¶é›†æ ‡ç­¾"""
        logger.info(f"å¼€å§‹åŸºäºæ¨èæµçš„æ·±åº¦ä¼˜å…ˆæ ‡ç­¾æ”¶é›† (æœ€å¤§æ·±åº¦: {self.max_depth})")

        start_time = time.time()
        initial_tag_count = self.storage.get_memory_count()

        try:
            # 1. è·å–æ¨èæ’ç”»ä½œä¸ºèµ·ç‚¹
            logger.info("è·å–æ¨èæ’ç”»...")
            try:
                recommended_illusts = self.search_api.get_recommended_illusts(limit=30)
            except Exception as e:
                if "429" in str(e) or "Too Many Requests" in str(e):
                    logger.error(f"è·å–æ¨èæ’ç”»æ—¶é‡åˆ°429é”™è¯¯: {e}")
                    logger.error("è¯·ç¨åå†è¯•ï¼Œæˆ–å‡å°‘è¯·æ±‚é¢‘ç‡")
                    return 0
                else:
                    logger.error(f"è·å–æ¨èæ’ç”»å¤±è´¥: {e}")
                    return 0

            if not recommended_illusts:
                logger.error("æ— æ³•è·å–æ¨èæ’ç”»ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ...")
                return 0

            logger.info(f"è·å–åˆ° {len(recommended_illusts)} ä¸ªæ¨èæ’ç”»")

            # 2. ä»æ¨èæ’ç”»ä¸­æå–åˆå§‹æ ‡ç­¾
            initial_tags = self._process_illusts(recommended_illusts, 0)
            logger.info(f"ä»æ¨èæ’ç”»ä¸­æå–åˆ° {len(initial_tags)} ä¸ªåˆå§‹æ ‡ç­¾")

            if not initial_tags:
                logger.warning("æ¨èæ’ç”»ä¸­æ²¡æœ‰å‘ç°æ–°æ ‡ç­¾")
                return 0

            # 3. æ·±åº¦ä¼˜å…ˆæœç´¢
            logger.info(f"å¼€å§‹æ·±åº¦ä¼˜å…ˆæœç´¢ï¼Œåˆå§‹æ ‡ç­¾æ•°é‡: {len(initial_tags)}")
            stats = self._dfs_collect_tags(initial_tags)

            # 4. å¼ºåˆ¶ä¿å­˜æœ€ç»ˆç»“æœ
            self._try_save(force=True)

            # 5. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            final_tag_count = self.storage.get_memory_count()
            total_new_count = final_tag_count - initial_tag_count
            total_time = time.time() - start_time

            # é¢‘ç‡ç»Ÿè®¡
            all_tags = self.storage.get_memory_tags()
            total_frequency = sum(tag.frequency for tag in all_tags)
            avg_frequency = total_frequency / len(all_tags) if all_tags else 0

            logger.info("ğŸ‰ æ·±åº¦ä¼˜å…ˆæ”¶é›†å®Œæˆï¼")
            logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {total_time / 60:.1f} åˆ†é’Ÿ")
            logger.info(f"ğŸ·ï¸  æ–°å‘ç°æ ‡ç­¾: {total_new_count} ä¸ª")
            logger.info(f"ğŸ“Š æ€»æ ‡ç­¾æ•°: {final_tag_count} ä¸ª")
            logger.info(
                f"ğŸ“ˆ é¢‘ç‡ç»Ÿè®¡: æ€»å‡ºç°æ¬¡æ•° {total_frequency}ï¼Œå¹³å‡é¢‘ç‡ {avg_frequency:.1f}"
            )
            logger.info(f"ğŸ” æœç´¢æ ‡ç­¾æ•°: {stats.tags_searched} ä¸ª")
            logger.info(f"ğŸ¨ å¤„ç†æ’ç”»æ•°: {stats.illusts_processed} ä¸ª")
            logger.info(f"ğŸ“ æœ€å¤§æ·±åº¦: {stats.depth_reached}")

            if total_time > 0:
                tags_per_minute = (stats.tags_searched * 60) / total_time
                logger.info(f"âš¡ æœç´¢é€Ÿåº¦: {tags_per_minute:.1f} æ ‡ç­¾/åˆ†é’Ÿ")

            return total_new_count

        except Exception as e:
            logger.error(f"æ·±åº¦ä¼˜å…ˆæ”¶é›†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            # å°è¯•ä¿å­˜å·²æ”¶é›†çš„æ•°æ®
            self._try_save(force=True)
            raise

    def load_existing_data(self):
        """åŠ è½½ç°æœ‰æ•°æ®ï¼ˆæ¨èæ¨¡å¼ä¸ºæ— çŠ¶æ€ï¼Œä¸éœ€è¦åŠ è½½è¿›åº¦ï¼‰"""
        existing_tags = self.storage.get_memory_tags()
        logger.info(f"å½“å‰å­˜å‚¨ä¸­æœ‰ {len(existing_tags)} ä¸ªæ ‡ç­¾")
        # æ¨èæ¨¡å¼æ˜¯æ— çŠ¶æ€çš„ï¼Œä¸éœ€è¦ç»´æŠ¤å»é‡é›†åˆ
